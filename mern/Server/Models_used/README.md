# Advanced Multiâ€‘Class Image Classification with Transfer Learning

This repository implements a **robust, productionâ€‘ready multiâ€‘class image classification pipeline** using **TensorFlow / Keras**. The system is designed for high accuracy, strong generalization, and realâ€‘world deployment by combining **transfer learning, advanced data augmentation, mixup, and twoâ€‘phase fineâ€‘tuning**.

---

## ğŸ“Œ Key Highlights

* Multiâ€‘class image classification (singleâ€‘label)
* Transfer learning using **ResNet50 / EfficientNetB0**
* Advanced `tf.data` input pipeline
* Strong data augmentation + **MixUp**
* Twoâ€‘phase training (frozen base â†’ fineâ€‘tuning)
* Mixed precision training for speed and efficiency
* Precision, Recall, Confusion Matrix & Classification Report
* Scalable and GPUâ€‘optimized

---

## ğŸ“‚ Dataset Structure

The dataset must follow a **directoryâ€‘based class structure**:

```
training_set/
 â”œâ”€â”€ class_1/
 â”œâ”€â”€ class_2/
 â”œâ”€â”€ class_3/

test_set/
 â”œâ”€â”€ class_1/
 â”œâ”€â”€ class_2/
 â”œâ”€â”€ class_3/
```

Each subâ€‘folder name represents a **class label**. The number of classes is detected automatically.

---

## âš™ï¸ Environment & Performance Optimization

### Mixed Precision Training

```python
set_global_policy('mixed_float16')
```

* Uses both **float16 and float32** automatically
* Reduces GPU memory usage
* Significantly speeds up training on modern GPUs

---

## ğŸ§¹ Dataset Cleaning (Corrupted Image Removal)

Before training, all images are verified and corrupted files are removed.

### Why this is important

* Prevents training crashes
* Ensures dataset integrity
* Avoids silent data corruption

```python
with Image.open(file_path) as img:
    img.verify()
```

This step is applied to both **training** and **test** directories.

---

## ğŸ§ª Test Data Generator (Evaluation Only)

```python
ImageDataGenerator(rescale=1./255)
```

* Only normalization is applied
* No augmentation (to ensure fair evaluation)
* `shuffle=False` ensures correct label alignment during evaluation

---

## ğŸš€ Training Data Pipeline (`tf.data`)

Instead of `ImageDataGenerator`, the training pipeline uses **TensorFlowâ€™s `tf.data` API** for efficiency and scalability.

### 1ï¸âƒ£ Image Loading & Preprocessing

```python
load_and_preprocess_image()
```

Operations:

* Read image from disk
* Decode JPEG
* Resize to `224Ã—224`
* Normalize pixel values (0â€“1)
* Convert label to oneâ€‘hot encoding

---

### 2ï¸âƒ£ Data Augmentation

```python
augment()
```

Applied randomly during training:

* Horizontal flip
* Random brightness
* Random contrast
* Random saturation
* Random rotation
* Random crop + resize (zoom simulation)

**Purpose:**

* Reduce overfitting
* Improve robustness to realâ€‘world variations

---

### 3ï¸âƒ£ MixUp Augmentation (Advanced)

```python
mixup()
```

MixUp blends two images and their labels:

```
image = Î»Â·imageâ‚ + (1âˆ’Î»)Â·imageâ‚‚
label = Î»Â·labelâ‚ + (1âˆ’Î»)Â·labelâ‚‚
```

**Benefits:**

* Smoother decision boundaries
* Better generalization
* Reduced model overconfidence

---

### 4ï¸âƒ£ Dataset Creation

```python
create_dataset()
```

Pipeline steps:

* Load file paths & labels
* Apply preprocessing
* Shuffle (training only)
* Apply augmentation
* Batch with fixed size
* Apply MixUp (optional)
* Repeat dataset infinitely
* Prefetch for GPU efficiency

This ensures **continuous, highâ€‘performance training**.

---

## ğŸ§  Model Architecture (Transfer Learning)

### Backbone Networks

* **ResNet50** (default)
* **EfficientNetB0** (optional)

Pretrained on **ImageNet** and used as feature extractors.

---

### Classification Head

```
Backbone CNN
â†“
Global Average Pooling
â†“
Batch Normalization
â†“
Dense (ReLU + L2 Regularization)
â†“
Batch Normalization
â†“
Dropout
â†“
Dense (Softmax Output)
```

**Design choices:**

* L2 regularization â†’ prevents overfitting
* Dropout â†’ improves generalization
* Softmax â†’ multiâ€‘class probability output

---

## ğŸ¯ Loss Function & Metrics

```python
CategoricalCrossentropy(label_smoothing=0.1)
```

* Suitable for **multiâ€‘class classification**
* Label smoothing stabilizes training

Metrics:

* Accuracy
* Precision
* Recall

---

## ğŸ§© Distributed Training

```python
tf.distribute.MirroredStrategy()
```

* Enables multiâ€‘GPU training automatically
* Works seamlessly on singleâ€‘GPU systems

---

## ğŸ‹ï¸ Twoâ€‘Phase Training Strategy

### ğŸ”¹ Phase 1: Train Classification Head

* Backbone frozen
* Only top layers are trained
* Faster convergence
* Stable feature learning

Callbacks used:

* EarlyStopping
* ReduceLROnPlateau
* TensorBoard logging

---

### ğŸ”¹ Phase 2: Fineâ€‘Tuning

* Last 30 layers of backbone unfrozen
* Lower learning rate
* Learns datasetâ€‘specific features
* Improves final accuracy

---

## ğŸ’¾ Model Saving

```python
model.save('pp6v5_finetuned.keras')
```

* Saves architecture + weights + optimizer state
* Ready for deployment or inference

---

## ğŸ“Š Model Evaluation

The model is evaluated on the **unseen test set** using:

* Test accuracy & loss
* Precision & recall
* Classification report (per class)
* Confusion matrix

This provides a **complete performance analysis**.

---

## âœ… Classification Type

* **Multiâ€‘class** classification
* **Singleâ€‘label** per image
* Softmax output layer

---

## ğŸ Conclusion

This pipeline is designed for **highâ€‘quality image classification projects**, suitable for:

* Finalâ€‘year academic projects
* Research experiments
* Realâ€‘world deployment
* Productionâ€‘level deep learning systems

It combines **modern best practices** in data handling, model training, and evaluation to achieve reliable and scalable results.

---

â­ If you find this useful, consider starring the repository!
